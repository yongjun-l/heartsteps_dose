---
title: "Optimal Dose for mHealth Interventions"
author: "Yongjun Lee"
format: html
editor: visual
header-includes:
  - \usepackage{amsmath}
  - \usepackage{amssymb}
  - \usepackage{bbm}
---



# Introduction 

Mobile health (mHealth) refers to the use of mobile devices, such as smartphones and wearable devices, to deliver healthcare services and interventions, and also detect the current health status of the individual. These interventions are usually intended to promote healthy behavioral change. For example, we may consider sending smartphone push notification for medication reminders or physical activity suggestions for sedentary workers. The efficacy of these interventions are analyzed through microrandomized studies where participants are randomized to treatment (e.g. push notification) multiple times throughout the day, and outcome is also recorded through a smart device (e.g. step count).

In the mHealth literature, previous research has examined the delayed effects of notifications or the immediate treatment effect within a 30-minute window following an intervention. However, focusing on a single treatment effect may not be reliable since too few number of treatments might not be sufficient for the desired outcome, while an excessive number of treatments could lead to participant fatigue, potentially resulting in adverse effects. To address this issue, I am in the process of developing a method to efficiently analyze the optimal "dose" of daily treatment.

The estimand of interest is the dose effect which is defined by $\mathbb{E}[Y(dose)-Y(0)|S] = S^{\top}\beta$, where $Y(dose)$ is the outcome under treatment $d$, $Y(0)$ is the outcome under no treatment, and $S$ is the vector of features that affect the outcome. It can be shown that the dose effect can be estimated by solving the following estimating equation. 
$$
\tilde{u}=\sum_{t=1}^{T}\sum_{k=1}^{K} \frac{1}{{k \choose d}} \sum_{\bar{a}_{k}\in \mathcal{D}}\left(\frac{\mathbbm{1}(\bar{A}_{k}=\bar{a}_{k})}{\mathbb{P}(\bar{A}_{k}=\bar{a}_{k})} \left( Y_{t,k}-m_{1} \right) -\frac{\mathbbm{1}(\bar{A}_{k}=\bar{0}_{k})}{\mathbb{P}(\bar{A}_{k}=\bar{0}_{k})} \left( Y_{t,k}-m_{0} \right) + m_{1} - m_{2}- \frac{1}{K} S^{\top}\beta\right)\nu(S) 
$$
Here, $T$ is total number of follow-up days, $K$ is the number of randomization time points within a day, $\bar{a}_{k}$ is the treatment regime up to time $k$, $\mathcal{D}$ is the set of all treatment regimes for dose $d$, $\bar{A}_{k}$ is the observed treatment vector for day $t$, up to decision point $k$, $Y_{t,k}$ is the outcome on day $t$ at decision point $k$, $m_{1}$ is the predicted outcome regression model of the outcome with baseline covariates had everyone received treatment $k$, and $m_{0}$ is the predicted outcome from same regression model under no treatment, $S$ is the set of pre-randomization effect modifying variables, and $\beta$ is the dose effect. 




# Code Improvement 1 - Vectorization
![Profvis Screen](/profvis1.png)
The above profvis output shows that the bottleneck of the code is for computing $\mathbbm{1}(\bar{A}_{k}=\bar{a}_{k})$ and $\mathbbm{1}(\bar{A}_{k}=\bar{0}_{k})$. Thse two indicators identify the individuals who received the treatment regime $\bar{a}_{k}$ and those who received no treatment until decision point $k$. The current implementation uses `apply` function that loops to iterate over each individual and check if the treatment regime is equal to $\bar{a}_{t}$ or $\bar{0}_{t}$. Also, it creates `rep(0,decision)` for each iteration which adds to memory allocation and deallocation overhead.
``` r
I_at <- apply(a[, 1:decision, drop=FALSE], 1, 
function(x) all(x == a_5[regime,1:decision]))
I_0t <- apply(a[, 1:decision, drop=FALSE], 1, 
function(x) all(x == rep(0, decision)))
```
This is inefficient since the code is not vectorized and `all()` function is run for every iteration. To improve the code, I vectorized the code so that it check the entire matrix at once. Also, I predefined `zeros` vectors to reduce overhead cost. The new code snippet and the resulting benchmark is shown below. The new code is almost 3 times faster than the original code.
```r
I_at <- rowSums(a[, 1:decision, drop=FALSE] == matrix(a_5[regime, 1:decision], 
nrow=nrow(a), ncol=decision, byrow=TRUE)) == decision
I_0t <- rowSums(a[, 1:decision, drop=FALSE] == matrix(zeros[[decision]], 
nrow=nrow(a), ncol=decision, byrow=TRUE)) == decision
```

```{r, echo=FALSE, warning=FALSE,message=FALSE}
source("main.R")
filename <- "seventh_setting_n50_m100_days10_t5_p0.5_beta20_dose1.rds"
#dfs <- readRDS(paste("GITHUB_WORKSPACE/simulated_data",filename, sep = "/"))
dfs <- readRDS(filename)
m <- length(dfs)
ee.6.4 <- matrix(nrow = m, ncol = 3)
ee.6.4.improved <- matrix(nrow = m, ncol = 3)


dose=1
m=1
setting = 7
#debugonce(main)
# main(m, setting, dfs)
# 
# profvis::profvis({
#   main(m, setting, dfs)
# })
# benchmark ee.cor.1, and ee.cor.2
data <- dfs[[1]]$df
y <- data[,c("Y1", "Y2", "Y3", "Y4", "Y5")]
a <- data[,c("a1", "a2", "a3", "a4", "a5")]
h <- data[,c("h1", "h2", "h3")]
s <- data[,c("s1", "s2", "s3")]
p <- 0.5
matrix <- get_p_a(a, p)
cum_d <- matrix$cum_d
p_a <- matrix$p_a

bench <- bench::mark(
  ee6.4( c(0,0,0), y, a, h, s, p_a, cum_d, dose ),
  ee6.4.improved( c(0,0,0), y, a, h, s, p_a, cum_d, dose ), relative = TRUE
)
library(kableExtra)
kable(cbind(func=c("Original", "Improved"), bench[,c("min","median","itr/sec","n_itr","total_time")])) %>%
  kable_styling("striped", full_width = F)
```
# Code Improvement 2 - Parallel Computing
To estimate the variance of our estimator, we use bootstrapping method where multiple datasets are generated and we calculate the empirical standard error of the estimated value for each dataset. Since each bootstrapping iteration is not dependent of each other, this is optimal for applying the parallelization technique. This can be easily implemented by replacing the `for` loop with `mclapply    ` function from `parallel` package. The resulting benchmark is shown below. The parallelized code is also two times faster than the original code.

```{r, echo=FALSE, warning=FALSE,message=FALSE}
source("compare_parallel.R")
bench_parallel <- bench::mark(
  main.linear(dfs, m=10),
  main.parallel(dfs, m=10), relative = TRUE, memory=FALSE
)

kable(cbind(func=c("Original", "Improved"), bench_parallel[,c("min","median","itr/sec","n_itr","total_time")])) %>%
  kable_styling("striped", full_width = F)
```

# Simlations
Some simulations were carried out to verify the consistency of our method and also to check the computaion time for differing sample size and simulation iterations. The data generating process is:
$$Y_t = H\eta+S\beta a_t+\epsilon$$
where $H = (\bar{h}_1, \bar{h}_2, \bar{h}_3), h_1 = \bar{1}_n, h_2\sim Normal(0,1), h_3= h_2^2,\eta=(30,20,10), S =(s_1, s_2, s_3), s_1 = \bar{1}_n, s_2 \sim Binom(0.5), s_3 \sim Normal(0,1), \beta=(20,10,5), \epsilon\sim Normal(0,1)$ and $a_t$ is the treatment regime at time $t$. The data is generated for $n=50,100$ individuals, $t=10,20$ days, $m=100,200$ simulations. The dose effect is $\beta=(20,10,5)$ and the dose is $1$. The resulting simulation results show consistency, and the computation time is linear with respect to the number of individuals and days. 

```{r, echo=FALSE, warning=FALSE,message=FALSE}
filename <- "seventh_setting_n50_m100_days10_t5_p0.5_beta20_dose1.rds"
#dfs <- readRDS(paste("GITHUB_WORKSPACE/simulated_data",filename, sep = "/"))
dfs <- readRDS(filename)
timestart <- Sys.time()
m=100
ee.6.4 <- main.parallel(dfs, m)
timeend <- Sys.time()
run.1 <- timeend - timestart
means <- colMeans(ee.6.4)
rslt1 <- c(50, 10, m, 20, means[1], sd(ee.6.4[,1]), 10, means[2], sd(ee.6.4[,2]), 5, means[3], sd(ee.6.4[,3]), run.1)

filename <- "seventh_setting_n100_m100_days20_t5_p0.5_beta20_dose1.rds"
#dfs <- readRDS(paste("GITHUB_WORKSPACE/simulated_data",filename, sep = "/"))
m=100
dfs <- readRDS(filename)
timestart2 <- Sys.time()
ee.6.4 <- main.parallel(dfs, m)
timeend2 <- Sys.time()
run.2 <- timeend2 - timestart2
means <- colMeans(ee.6.4)
rslt2 <- c(100, 20, m, 20, means[1], sd(ee.6.4[,1]), 10, means[2], sd(ee.6.4[,2]), 5, means[3], sd(ee.6.4[,3]), run.2)

filename <- "seventh_setting_n100_m200_days20_t5_p0.5_beta20_dose1.rds"
#dfs <- readRDS(paste("GITHUB_WORKSPACE/simulated_data",filename, sep = "/"))
dfs <- readRDS(filename)
m=200
timestart3 <- Sys.time()
ee.6.4 <- main.parallel(dfs, m)
timeend3 <- Sys.time()
run.3 <- timeend3 - timestart3
means <- colMeans(ee.6.4)
rslt3 <- c(100, 20, m, 20, means[1], sd(ee.6.4[,1]), 10, means[2], sd(ee.6.4[,2]), 5, means[3], sd(ee.6.4[,3]), run.3)

rslt <- rbind(rslt1, rslt2, rslt3)
colnames(rslt) <- c("n", "days", "m", "beta1", "hat1", "sd1", "beta2","hat2", "sd2", "beta3", "hat3", "sd3", "runtime")
kable(rslt[,c(1,2,3,4,5,6,13)]) %>%
  kable_styling("striped", full_width = F)
```



